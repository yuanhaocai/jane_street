{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datananme = 'js'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47127338, 93)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data using pd\n",
    "\n",
    "# pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# the data is stored in the parent dir with dir_name being datananme\n",
    "train_pd = pd.read_parquet(f'../{datananme}/train.parquet/')\n",
    "train_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data using pl\n",
    "\n",
    "train_pl = pl.read_parquet(f'../{datananme}/train.parquet/')\n",
    "train_pl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data checking/visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# missing values for all of the features for rows that 'responder_6'\n",
    "# is not None\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "\n",
    "supervised_usable = (\n",
    "    train_pl\n",
    "    .filter(pl.col('responder_6').is_not_null())\n",
    ")\n",
    "\n",
    "missing_count = (\n",
    "    supervised_usable\n",
    "    .null_count()\n",
    "    .transpose(include_header=True,\n",
    "               header_name='feature',\n",
    "               column_names=['null_count'])\n",
    "    .sort('null_count', descending=True)\n",
    "    .with_columns((pl.col('null_count') / len(supervised_usable)).alias('null_ratio'))\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 20))\n",
    "plt.title(f'Missing values over the {len(supervised_usable)} samples which have a target')\n",
    "plt.barh(np.arange(len(missing_count)), missing_count.get_column('null_ratio'), color='coral', label='missing')\n",
    "plt.barh(np.arange(len(missing_count)), \n",
    "         1 - missing_count.get_column('null_ratio'),\n",
    "         left=missing_count.get_column('null_ratio'),\n",
    "         color='darkseagreen', label='available')\n",
    "plt.yticks(np.arange(len(missing_count)), missing_count.get_column('feature'))\n",
    "plt.gca().xaxis.set_major_formatter(PercentFormatter(xmax=1, decimals=0))\n",
    "plt.xlim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NaNs for 'responder_6'\n",
    "train_pd['responder_6'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# view lags.parquet\n",
    "\n",
    "lags_pd = pd.read_parquet(f'../{datananme}/lags.parquet/date_id=0')\n",
    "lags_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the sample test data\n",
    "\n",
    "test_pd = pd.read_parquet(f'../{datananme}/test.parquet/date_id=0/part-0.parquet')\n",
    "test_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some features\n",
    "\n",
    "col_to_drop = [f'responder_{i}' for i in range(9) if i != 6] \\\n",
    "                + ['partition_id']\n",
    "\n",
    "train_pd1 = train_pd.drop(labels=col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35370822, 84)\n"
     ]
    }
   ],
   "source": [
    "# drop rows with NAs\n",
    "# but perhaps no need? xgboost shall be able to handle NA by default\n",
    "\n",
    "train_pd2 = train_pd1.dropna(axis=0)\n",
    "print(train_pd2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to predictors and y, since there is no categorical features\n",
    "\n",
    "col_weight = ['weight']\n",
    "col_y = ['responder_6']\n",
    "col_num = [col for col in train_pd2.columns.tolist() if col not in col_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_r2(y_true, y_pred, weights):\n",
    "#     \"\"\"\n",
    "#     Args:\n",
    "#         y_true, y_pred, weights: np.arrays.\n",
    "#     \"\"\"\n",
    "#     numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
    "#     denominator = np.sum(weights * (y_true ** 2))\n",
    "#     r2_score = 1 - (numerator / denominator)\n",
    "#     return r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------"
     ]
    }
   ],
   "source": [
    "def calculate_r2_batched(y_true, y_pred, weights, batch_size=100000):\n",
    "    \"\"\"\n",
    "    Calculate the weighted R^2 score using small batches.\n",
    "    \n",
    "    Args:\n",
    "        y_true, y_pred, weights: np.arrays.\n",
    "    \"\"\"\n",
    "    total_weighted_error = 0\n",
    "    total_weighted_square_true = 0\n",
    "    num_batches = int(np.ceil(len(y_true) / batch_size))\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = min((i + 1) * batch_size, len(y_true))\n",
    "\n",
    "        y_true_batch = y_true[start:end]\n",
    "        y_pred_batch = y_pred[start:end]\n",
    "        weights_batch = weights[start:end]\n",
    "\n",
    "        numerator_batch = np.sum(weights_batch * (y_true_batch - y_pred_batch) ** 2)\n",
    "        denominator_batch = np.sum(weights_batch * y_true_batch ** 2)\n",
    "\n",
    "        total_weighted_error += numerator_batch\n",
    "        total_weighted_square_true += denominator_batch\n",
    "        \n",
    "        print('-', end='') # TEST\n",
    "\n",
    "    r2_score = 1 - (total_weighted_error / total_weighted_square_true)\n",
    "    return r2_score\n",
    "\n",
    "r2_score = calculate_r2_batched(y_valid.to_numpy(), y_valid_pred, w_valid.to_numpy())\n",
    "r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def time_series_cross_validation(date_ids, n_splits):\n",
    "    fold_size = len(date_ids) // n_splits\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        # Here, the training set includes all data up to i-th fold\n",
    "        end_train = (i + 1) * fold_size\n",
    "        train_dates = date_ids[:end_train]\n",
    "        # Validation dates are the next fold_size data points after the training set\n",
    "        valid_dates = date_ids[end_train:end_train + fold_size] if end_train + fold_size <= len(date_ids) else date_ids[end_train:]\n",
    "        \n",
    "        yield train_dates, valid_dates\n",
    "        \n",
    "\n",
    "# date_ids = train_pd2['date_id'].unique()\n",
    "\n",
    "# n_splits = 5\n",
    "\n",
    "# for train_dates, valid_dates in time_series_cross_validation(date_ids, n_splits):\n",
    "#     print(\"Train Dates:\", train_dates)\n",
    "#     print(\"Valid Dates:\", valid_dates)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.80886\tvalid-rmse:0.85211\n",
      "[10]\ttrain-rmse:0.74917\tvalid-rmse:0.91122\n",
      "[20]\ttrain-rmse:0.69859\tvalid-rmse:0.98388\n",
      "[30]\ttrain-rmse:0.66358\tvalid-rmse:1.02927\n",
      "[40]\ttrain-rmse:0.63271\tvalid-rmse:1.06170\n",
      "[50]\ttrain-rmse:0.60450\tvalid-rmse:1.09480\n",
      "[60]\ttrain-rmse:0.57909\tvalid-rmse:1.12086\n",
      "[70]\ttrain-rmse:0.55682\tvalid-rmse:1.13795\n",
      "[80]\ttrain-rmse:0.53793\tvalid-rmse:1.15427\n",
      "[90]\ttrain-rmse:0.52049\tvalid-rmse:1.16452\n",
      "[99]\ttrain-rmse:0.50372\tvalid-rmse:1.18246\n",
      "[0]\ttrain-rmse:0.82528\tvalid-rmse:0.82750\n",
      "[10]\ttrain-rmse:0.77882\tvalid-rmse:0.85390\n",
      "[20]\ttrain-rmse:0.74762\tvalid-rmse:0.90764\n",
      "[30]\ttrain-rmse:0.72051\tvalid-rmse:0.92927\n",
      "[40]\ttrain-rmse:0.69606\tvalid-rmse:0.95881\n",
      "[50]\ttrain-rmse:0.67815\tvalid-rmse:0.98269\n",
      "[60]\ttrain-rmse:0.65932\tvalid-rmse:1.00400\n",
      "[70]\ttrain-rmse:0.64268\tvalid-rmse:1.04444\n",
      "[80]\ttrain-rmse:0.62631\tvalid-rmse:1.05778\n",
      "[90]\ttrain-rmse:0.61182\tvalid-rmse:1.08960\n",
      "[99]\ttrain-rmse:0.59673\tvalid-rmse:1.10067\n",
      "[0]\ttrain-rmse:0.82289\tvalid-rmse:0.76226\n",
      "[10]\ttrain-rmse:0.78786\tvalid-rmse:0.79129\n",
      "[20]\ttrain-rmse:0.76349\tvalid-rmse:0.81616\n",
      "[30]\ttrain-rmse:0.74394\tvalid-rmse:0.84653\n",
      "[40]\ttrain-rmse:0.72597\tvalid-rmse:0.86254\n",
      "[50]\ttrain-rmse:0.71124\tvalid-rmse:0.88460\n",
      "[60]\ttrain-rmse:0.69987\tvalid-rmse:0.89781\n",
      "[70]\ttrain-rmse:0.68412\tvalid-rmse:0.91450\n",
      "[80]\ttrain-rmse:0.66949\tvalid-rmse:0.93081\n",
      "[90]\ttrain-rmse:0.65653\tvalid-rmse:0.94715\n",
      "[100]\ttrain-rmse:0.64322\tvalid-rmse:0.96041\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[16:03:39] /workspace/src/c_api/../data/../common/device_helpers.cuh:431: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n- Free memory: 4877320192\n- Requested memory: 5237352456\n\nStack trace:\n  [bt] (0) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x77f79a) [0x7f8a0aed379a]\n  [bt] (1) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x783994) [0x7f8a0aed7994]\n  [bt] (2) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x79d5ca) [0x7f8a0aef15ca]\n  [bt] (3) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x7d1df4) [0x7f8a0af25df4]\n  [bt] (4) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x7d1f44) [0x7f8a0af25f44]\n  [bt] (5) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0xad5fa7) [0x7f8a0b229fa7]\n  [bt] (6) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0xad7167) [0x7f8a0b22b167]\n  [bt] (7) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x45bfb2) [0x7f8a0abaffb2]\n  [bt] (8) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4c894d) [0x7f8a0ac1c94d]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 45\u001b[0m\n\u001b[1;32m     31\u001b[0m dvalid \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_valid, label\u001b[38;5;241m=\u001b[39my_valid, weight\u001b[38;5;241m=\u001b[39mw_valid)\n\u001b[1;32m     33\u001b[0m XGB_PARAMS \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_metric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     43\u001b[0m }\n\u001b[0;32m---> 45\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXGB_PARAMS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m y_valid_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dvalid)\n",
      "File \u001b[0;32m~/.conda/envs/js/lib/python3.10/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/js/lib/python3.10/site-packages/xgboost/training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    185\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m~/.conda/envs/js/lib/python3.10/site-packages/xgboost/callback.py:238\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset name should not contain `-`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 238\u001b[0m score: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n",
      "File \u001b[0;32m~/.conda/envs/js/lib/python3.10/site-packages/xgboost/core.py:2125\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m   2123\u001b[0m evnames \u001b[38;5;241m=\u001b[39m c_array(ctypes\u001b[38;5;241m.\u001b[39mc_char_p, [c_str(d[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[1;32m   2124\u001b[0m msg \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[0;32m-> 2125\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2136\u001b[0m res \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/js/lib/python3.10/site-packages/xgboost/core.py:282\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [16:03:39] /workspace/src/c_api/../data/../common/device_helpers.cuh:431: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n- Free memory: 4877320192\n- Requested memory: 5237352456\n\nStack trace:\n  [bt] (0) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x77f79a) [0x7f8a0aed379a]\n  [bt] (1) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x783994) [0x7f8a0aed7994]\n  [bt] (2) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x79d5ca) [0x7f8a0aef15ca]\n  [bt] (3) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x7d1df4) [0x7f8a0af25df4]\n  [bt] (4) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x7d1f44) [0x7f8a0af25f44]\n  [bt] (5) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0xad5fa7) [0x7f8a0b229fa7]\n  [bt] (6) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0xad7167) [0x7f8a0b22b167]\n  [bt] (7) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x45bfb2) [0x7f8a0abaffb2]\n  [bt] (8) /home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4c894d) [0x7f8a0ac1c94d]\n\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "# cross-validation on dates\n",
    "import xgboost as xgb\n",
    "\n",
    "## some hyperparameters \n",
    "verbose_eval = 10\n",
    "early_stopping_rounds = 100\n",
    "num_boost_round = 1000\n",
    "\n",
    "## main part\n",
    "date_ids = train_pd2['date_id'].unique()\n",
    "k = 5\n",
    "fold_size = date_ids.shape[0] // k\n",
    "\n",
    "# for i in range(k):\n",
    "#     start = i * fold_size\n",
    "#     end = (i + 1) * fold_size if i != k - 1 else len(date_ids_ls)\n",
    "#     valid_dates = date_ids[start:end]\n",
    "#     train_dates = np.concatenate([date_ids[:start], date_ids[end:]])\n",
    "\n",
    "for train_dates, valid_dates in time_series_cross_validation(date_ids, n_splits):\n",
    "    X_train = train_pd2[col_num].loc[train_pd2['date_id'].isin(train_dates)]\n",
    "    y_train = train_pd2[col_y].loc[train_pd2['date_id'].isin(train_dates)]\n",
    "    w_train = train_pd2[col_weight].loc[train_pd2['date_id'].isin(train_dates)]\n",
    "\n",
    "    X_valid = train_pd2[col_num].loc[train_pd2['date_id'].isin(valid_dates)]\n",
    "    y_valid = train_pd2[col_y].loc[train_pd2['date_id'].isin(valid_dates)]\n",
    "    w_valid = train_pd2[col_weight].loc[train_pd2['date_id'].isin(valid_dates)]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, weight=w_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid, weight=w_valid)\n",
    "\n",
    "    XGB_PARAMS = {\n",
    "        'eval_metric': 'rmse',\n",
    "        'learning_rate': 0.5,\n",
    "        'max_depth': 12,\n",
    "        'min_child_weight': 1.5,\n",
    "        'subsample': 0.8555,\n",
    "        'colsample_bytree': 0.85555555,\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda'\n",
    "    }\n",
    "\n",
    "    model = xgb.train(XGB_PARAMS, dtrain, num_boost_round=num_boost_round, evals=[(dtrain, 'train'), (dvalid, 'valid')], early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose_eval)\n",
    "\n",
    "    y_valid_pred = model.predict(dvalid)\n",
    "#     r2_score = calculate_r2_batched(y_valid.to_numpy(), y_valid_pred, w_valid.to_numpy())\n",
    "#     print(f\"Fold {fold_idx} validation R2 score: {r2_score}\")\n",
    "    print('\\nFold completed \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test xgboost\n",
    "# import xgboost as xgb\n",
    "# import numpy as np\n",
    "\n",
    "# # Generate some random data to simulate a training set\n",
    "# num_samples = 1000\n",
    "# num_features = 10\n",
    "\n",
    "# X = np.random.rand(num_samples, num_features)\n",
    "# y = np.random.randint(2, size=num_samples)\n",
    "\n",
    "# # Split data into training and evaluation sets\n",
    "# split_index = int(num_samples * 0.8)\n",
    "# X_train, X_eval = X[:split_index], X[split_index:]\n",
    "# y_train, y_eval = y[:split_index], y[split_index:]\n",
    "\n",
    "# # Create DMatrix for train and eval data\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# deval = xgb.DMatrix(X_eval, label=y_eval)\n",
    "\n",
    "# # Define the parameter dictionary, enabling the use of GPU\n",
    "# param = {\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'max_depth': 3,\n",
    "#     'eta': 0.1,\n",
    "#     'tree_method': 'hist',  # Specify 'gpu_hist' to enable GPU support\n",
    "#     'eval_metric': 'logloss',\n",
    "#     'device': 'cuda:4'\n",
    "# }\n",
    "\n",
    "# # Number of boosting rounds\n",
    "# num_round = 10\n",
    "\n",
    "# # Create a watchlist to evaluate the performance of the model\n",
    "# evals = [(dtrain, 'train'), (deval, 'eval')]\n",
    "\n",
    "# # Train the model\n",
    "# bst = xgb.train(param, dtrain, num_round, evals)\n",
    "\n",
    "# # Print model information\n",
    "# print(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js",
   "language": "python",
   "name": "js"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
