{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datananme = 'js'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47127338, 93)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data using pd\n",
    "\n",
    "# pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# the data is stored in the parent dir with dir_name being datananme\n",
    "train_pd = pd.read_parquet(f'../{datananme}/train.parquet/')\n",
    "train_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data using pl\n",
    "\n",
    "train_pl = pl.read_parquet(f'../{datananme}/train.parquet/')\n",
    "train_pl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data checking/visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# missing values for all of the features for rows that 'responder_6'\n",
    "# is not None\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "\n",
    "supervised_usable = (\n",
    "    train_pl\n",
    "    .filter(pl.col('responder_6').is_not_null())\n",
    ")\n",
    "\n",
    "missing_count = (\n",
    "    supervised_usable\n",
    "    .null_count()\n",
    "    .transpose(include_header=True,\n",
    "               header_name='feature',\n",
    "               column_names=['null_count'])\n",
    "    .sort('null_count', descending=True)\n",
    "    .with_columns((pl.col('null_count') / len(supervised_usable)).alias('null_ratio'))\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 20))\n",
    "plt.title(f'Missing values over the {len(supervised_usable)} samples which have a target')\n",
    "plt.barh(np.arange(len(missing_count)), missing_count.get_column('null_ratio'), color='coral', label='missing')\n",
    "plt.barh(np.arange(len(missing_count)), \n",
    "         1 - missing_count.get_column('null_ratio'),\n",
    "         left=missing_count.get_column('null_ratio'),\n",
    "         color='darkseagreen', label='available')\n",
    "plt.yticks(np.arange(len(missing_count)), missing_count.get_column('feature'))\n",
    "plt.gca().xaxis.set_major_formatter(PercentFormatter(xmax=1, decimals=0))\n",
    "plt.xlim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NaNs for 'responder_6'\n",
    "train_pd['responder_6'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# view lags.parquet\n",
    "\n",
    "lags_pd = pd.read_parquet(f'../{datananme}/lags.parquet/date_id=0')\n",
    "lags_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the sample test data\n",
    "\n",
    "test_pd = pd.read_parquet(f'../{datananme}/test.parquet/date_id=0/part-0.parquet')\n",
    "test_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some features\n",
    "\n",
    "col_to_drop = [f'responder_{i}' for i in range(9) if i != 6] \\\n",
    "                + ['partition_id']\n",
    "\n",
    "train_pd1 = train_pd.drop(labels=col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35370822, 84)\n"
     ]
    }
   ],
   "source": [
    "# drop rows with NAs\n",
    "# but perhaps no need? xgboost shall be able to handle NA by default\n",
    "\n",
    "train_pd2 = train_pd1.dropna(axis=0)\n",
    "print(train_pd2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to predictors and y, since there is no categorical features\n",
    "\n",
    "col_weight = ['weight']\n",
    "col_y = ['responder_6']\n",
    "col_num = [col for col in train_pd2.columns.tolist() if col not in col_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r2(y_true, y_pred, weights):\n",
    "    numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
    "    denominator = np.sum(weights * (y_true ** 2))\n",
    "    r2_score = 1 - (numerator / denominator)\n",
    "    return r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cai00196/.conda/envs/js/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [04:20:22] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.77472\tvalid-rmse:0.82183\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "# cross-validation on dates\n",
    "import xgboost as xgb\n",
    "\n",
    "date_ids = train_pd2['date_id'].unique()\n",
    "k = 5\n",
    "fold_size = date_ids.shape[0] // k\n",
    "\n",
    "for i in range(k):\n",
    "    start = i * fold_size\n",
    "    end = (i + 1) * fold_size if i != k - 1 else len(date_ids_ls)\n",
    "    valid_dates = date_ids[start:end]\n",
    "    train_dates = np.concatenate([date_ids[:start], date_ids[end:]])\n",
    "    \n",
    "    X_train = train_pd2[col_num].loc[train_pd2['date_id'].isin(train_dates)]\n",
    "    y_train = train_pd2[col_y].loc[train_pd2['date_id'].isin(train_dates)]\n",
    "    w_train = train_pd2[col_weight].loc[train_pd2['date_id'].isin(train_dates)]\n",
    "\n",
    "    X_valid = train_pd2[col_num].loc[train_pd2['date_id'].isin(valid_dates)]\n",
    "    y_valid = train_pd2[col_y].loc[train_pd2['date_id'].isin(valid_dates)]\n",
    "    w_valid = train_pd2[col_weight].loc[train_pd2['date_id'].isin(valid_dates)]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, weight=w_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid, weight=w_valid)\n",
    "\n",
    "    XGB_PARAMS = {\n",
    "        'eval_metric': 'rmse',\n",
    "        'learning_rate': 0.5,\n",
    "        'max_depth': 12,\n",
    "        'min_child_weight': 1.5,\n",
    "        'subsample': 0.8555,\n",
    "        'colsample_bytree': 0.85555555,\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda'\n",
    "    }\n",
    "\n",
    "    model = xgb.train(XGB_PARAMS, dtrain, num_boost_round=1000, evals=[(dtrain, 'train'), (dvalid, 'valid')], early_stopping_rounds=100, verbose_eval=50)\n",
    "\n",
    "    y_valid_pred = model.predict(dvalid)\n",
    "    r2_score = calculate_r2(X_valid.to_numpy(), y_valid_pred, w_valid.to_numpy())\n",
    "    print(f\"Fold {fold_idx} validation R2 score: {r2_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js",
   "language": "python",
   "name": "js"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
